{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peternagy/anaconda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/peternagy/anaconda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, Flatten, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import RMSprop\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as pl\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform, conditional\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "\n",
    "from keras.objectives import binary_crossentropy\n",
    "from keras.metrics import binary_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "I have created this notebook to first observe the task with binary classification. This way it was easier to find the most \n",
    "promising features and algorithm to go with.\n",
    "I have found this (http://cs229.stanford.edu/proj2015/328_report.pdf) \"paper\" claiming that they have reached ~0.69\n",
    "accuracy with RandomForest on the same dataset. (Binary classification)\n",
    "I couldn't reproduce their result, not even with their best features. More suprisingly I didn't find their best features the best at all.\n",
    "With a fully connected Neural Network on the binary classification problem, my best result was ~0.63 accuracy.\n",
    "'''\n",
    "\n",
    "def data():\n",
    "    cols = [' title_sentiment_polarity', ' n_tokens_title', ' data_channel_is_lifestyle', ' data_channel_is_entertainment', ' data_channel_is_bus', ' data_channel_is_socmed', ' data_channel_is_tech', ' data_channel_is_world', ' weekday_is_monday', ' weekday_is_tuesday', ' weekday_is_wednesday', ' weekday_is_thursday', ' weekday_is_friday', ' weekday_is_saturday', ' weekday_is_sunday', ' is_weekend', ' global_sentiment_polarity', ' shares']\n",
    "    raw_data = pd.read_csv('data/OnlineNewsPopularity.csv', usecols=cols)\n",
    "    \n",
    "    #Standardize n_tokens_title\n",
    "    raw_data[' n_tokens_title'] -= raw_data[' n_tokens_title'].mean(axis=0)\n",
    "    raw_data[' n_tokens_title'] /= raw_data[' n_tokens_title'].std(axis=0)\n",
    "    \n",
    "    #Create two classes, they are roughly equal in number\n",
    "    def categorizeBinaryShares(shares):\n",
    "        if shares <= 1400:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "    raw_data['label'] = raw_data[' shares'].apply(categorizeBinaryShares)\n",
    "    raw_data['label'].value_counts()\n",
    "    raw_data.drop([' shares'], axis=1, inplace=True)\n",
    "    \n",
    "    y = raw_data['label']\n",
    "    raw_data.drop(['label'], axis=1, inplace=True)\n",
    "    \n",
    "    raw_data.fillna(\"\", inplace=True)\n",
    "    raw_data = raw_data.reindex()\n",
    "    \n",
    "    def constructBestFeatures(df):\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        if 'url' in raw_data.keys():\n",
    "            raw_data.drop(['url'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "        classifier = DecisionTreeClassifier()\n",
    "        classifier.fit(raw_data, y)\n",
    "\n",
    "\n",
    "        importances = []\n",
    "        for name, importance in zip(raw_data.columns, classifier.feature_importances_):\n",
    "            importances.append((name, importance))\n",
    "\n",
    "        num_cols = len(raw_data.columns)\n",
    "        importances_sorted = sorted(importances, key=lambda x: x[1])\n",
    "        importances_sorted\n",
    "        cols = []\n",
    "        #Getting the top 14 features\n",
    "        for imp_tupl in importances_sorted[-14:]:\n",
    "            cols.append(imp_tupl[0])\n",
    "        return cols\n",
    "\n",
    "    cols = constructBestFeatures(raw_data)\n",
    "    print(cols)\n",
    "    best_features = raw_data[cols]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(best_features, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense, Flatten, Dropout, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import EarlyStopping\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import to_categorical\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import RMSprop\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import os\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as pl\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform, conditional\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.objectives import binary_crossentropy\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.metrics import binary_accuracy\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.tree import DecisionTreeClassifier\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dense': hp.choice('Dense', [32,64, 128 ,256, 512, 1024]),\n",
      "        'Dense_1': hp.choice('Dense_1', [32,64, 128 ,256, 512, 1024]),\n",
      "        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),\n",
      "        'batch_size': hp.choice('batch_size', [32, 64, 128]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: cols = [' title_sentiment_polarity', ' n_tokens_title', ' data_channel_is_lifestyle', ' data_channel_is_entertainment', ' data_channel_is_bus', ' data_channel_is_socmed', ' data_channel_is_tech', ' data_channel_is_world', ' weekday_is_monday', ' weekday_is_tuesday', ' weekday_is_wednesday', ' weekday_is_thursday', ' weekday_is_friday', ' weekday_is_saturday', ' weekday_is_sunday', ' is_weekend', ' global_sentiment_polarity', ' shares']\n",
      "   3: raw_data = pd.read_csv('data/OnlineNewsPopularity.csv', usecols=cols)\n",
      "   4: \n",
      "   5: raw_data[' n_tokens_title'] -= raw_data[' n_tokens_title'].mean(axis=0)\n",
      "   6: raw_data[' n_tokens_title'] /= raw_data[' n_tokens_title'].std(axis=0)\n",
      "   7: \n",
      "   8: def categorizeBinaryShares(shares):\n",
      "   9:     if shares <= 1400:\n",
      "  10:         return 0\n",
      "  11:     else:\n",
      "  12:         return 1\n",
      "  13: \n",
      "  14: raw_data['label'] = raw_data[' shares'].apply(categorizeBinaryShares)\n",
      "  15: raw_data['label'].value_counts()\n",
      "  16: raw_data.drop([' shares'], axis=1, inplace=True)\n",
      "  17: \n",
      "  18: y = raw_data['label']\n",
      "  19: raw_data.drop(['label'], axis=1, inplace=True)\n",
      "  20: \n",
      "  21: raw_data.fillna(\"\", inplace=True)\n",
      "  22: raw_data = raw_data.reindex()\n",
      "  23: \n",
      "  24: def constructBestFeatures(df):\n",
      "  25:     from sklearn.tree import DecisionTreeClassifier\n",
      "  26:     if 'url' in raw_data.keys():\n",
      "  27:         raw_data.drop(['url'], axis=1, inplace=True)\n",
      "  28: \n",
      "  29: \n",
      "  30:     classifier = DecisionTreeClassifier()\n",
      "  31:     classifier.fit(raw_data, y)\n",
      "  32: \n",
      "  33: \n",
      "  34:     importances = []\n",
      "  35:     for name, importance in zip(raw_data.columns, classifier.feature_importances_):\n",
      "  36:         importances.append((name, importance))\n",
      "  37: \n",
      "  38:     num_cols = len(raw_data.columns)\n",
      "  39:     importances_sorted = sorted(importances, key=lambda x: x[1])\n",
      "  40:     importances_sorted\n",
      "  41:     cols = []\n",
      "  42:     #Getting the top 14 features\n",
      "  43:     for imp_tupl in importances_sorted[-14:]:\n",
      "  44:         cols.append(imp_tupl[0])\n",
      "  45:     return cols\n",
      "  46: \n",
      "  47: cols = constructBestFeatures(raw_data)\n",
      "  48: print(cols)\n",
      "  49: best_features = raw_data[cols]\n",
      "  50: \n",
      "  51: X_train, X_test, y_train, y_test = train_test_split(best_features, y, test_size=0.2, random_state=42)\n",
      "  52: \n",
      "  53: \n",
      "  54: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "  1: def keras_fmin_fnct(space):\n",
      "  2: \n",
      "  3:     print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
      "  4:     model = Sequential()\n",
      "  5:     model.add(Dense(64, kernel_initializer='random_uniform', activation='relu', input_dim=X_train.shape[1]))\n",
      "  6:     model.add(Dense(space['Dense'], activation='relu'))\n",
      "  7:     model.add(Dense(space['Dense_1'], activation='relu'))\n",
      "  8: \n",
      "  9:     model.add(Dense(1, activation='sigmoid'))\n",
      " 10:     model.compile(optimizer=space['optimizer'],\n",
      " 11:                   loss=binary_crossentropy, metrics=[binary_accuracy])\n",
      " 12:     history = model.fit(np.array(X_train), np.array(y_train), epochs=15, batch_size=space['batch_size'], validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', mode='auto')])\n",
      " 13:     score, acc = model.evaluate(np.array(X_test), np.array(y_test), verbose=0)\n",
      " 14:     print('Test accuracy:', acc)\n",
      " 15:     \n",
      " 16:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      " 17: \n",
      "[' data_channel_is_lifestyle', ' weekday_is_friday', ' data_channel_is_bus', ' data_channel_is_tech', ' weekday_is_monday', ' weekday_is_wednesday', ' weekday_is_tuesday', ' weekday_is_thursday', ' is_weekend', ' data_channel_is_world', ' data_channel_is_entertainment', ' n_tokens_title', ' title_sentiment_polarity', ' global_sentiment_polarity']\n",
      "(31715, 14) (31715,) (7929, 14) (7929,)\n",
      "Train on 28543 samples, validate on 3172 samples\n",
      "Epoch 1/15\n",
      "28543/28543 [==============================] - 0s - loss: 0.6910 - binary_accuracy: 0.5609 - val_loss: 0.6901 - val_binary_accuracy: 0.5495\n",
      "Epoch 2/15\n",
      "28543/28543 [==============================] - 0s - loss: 0.6867 - binary_accuracy: 0.5806 - val_loss: 0.6859 - val_binary_accuracy: 0.5753\n",
      "Epoch 3/15\n",
      "28543/28543 [==============================] - 0s - loss: 0.6805 - binary_accuracy: 0.5939 - val_loss: 0.6800 - val_binary_accuracy: 0.5801\n",
      "Epoch 4/15\n",
      "28543/28543 [==============================] - 0s - loss: 0.6730 - binary_accuracy: 0.6040 - val_loss: 0.6735 - val_binary_accuracy: 0.5949\n",
      "Epoch 5/15\n",
      "28543/28543 [==============================] - 0s - loss: 0.6659 - binary_accuracy: 0.6133 - val_loss: 0.6684 - val_binary_accuracy: 0.6028\n",
      "Epoch 6/15\n",
      "28543/28543 [==============================] - 0s - loss: 0.6608 - binary_accuracy: 0.6156 - val_loss: 0.6654 - val_binary_accuracy: 0.6034\n",
      "Epoch 7/15\n",
      "28543/28543 [==============================] - 0s - loss: 0.6578 - binary_accuracy: 0.6180 - val_loss: 0.6638 - val_binary_accuracy: 0.6050\n",
      "Epoch 8/15\n",
      "28543/28543 [==============================] - 0s - loss: 0.6561 - binary_accuracy: 0.6188 - val_loss: 0.6629 - val_binary_accuracy: 0.6100\n",
      "Epoch 9/15\n",
      "28543/28543 [==============================] - 0s - loss: 0.6552 - binary_accuracy: 0.6190 - val_loss: 0.6620 - val_binary_accuracy: 0.6088\n",
      "Epoch 10/15\n",
      "28543/28543 [==============================] - 0s - loss: 0.6545 - binary_accuracy: 0.6193 - val_loss: 0.6622 - val_binary_accuracy: 0.6107\n",
      "Test accuracy: 0.6234077437481162\n",
      "(31715, 14) (31715,) (7929, 14) (7929,)\n",
      "Train on 28543 samples, validate on 3172 samples\n",
      "Epoch 1/15\n",
      "28543/28543 [==============================] - 0s - loss: 0.6601 - binary_accuracy: 0.6076 - val_loss: 0.6626 - val_binary_accuracy: 0.6047\n",
      "Epoch 2/15\n",
      "28543/28543 [==============================] - 0s - loss: 0.6552 - binary_accuracy: 0.6186 - val_loss: 0.6605 - val_binary_accuracy: 0.6141\n",
      "Epoch 3/15\n",
      "28543/28543 [==============================] - 0s - loss: 0.6540 - binary_accuracy: 0.6204 - val_loss: 0.6659 - val_binary_accuracy: 0.6135\n",
      "Test accuracy: 0.6242905789101796\n",
      "(31715, 14) (31715,) (7929, 14) (7929,)\n",
      "Train on 28543 samples, validate on 3172 samples\n",
      "Epoch 1/15\n",
      "28543/28543 [==============================] - 1s - loss: 0.6602 - binary_accuracy: 0.6124 - val_loss: 0.6634 - val_binary_accuracy: 0.6050\n",
      "Epoch 2/15\n",
      "28543/28543 [==============================] - 0s - loss: 0.6549 - binary_accuracy: 0.6198 - val_loss: 0.6592 - val_binary_accuracy: 0.6195\n",
      "Epoch 3/15\n",
      "28543/28543 [==============================] - 0s - loss: 0.6541 - binary_accuracy: 0.6192 - val_loss: 0.6611 - val_binary_accuracy: 0.6138\n",
      "Test accuracy: 0.6260562492343063\n",
      "(31715, 14) (31715,) (7929, 14) (7929,)\n",
      "Train on 28543 samples, validate on 3172 samples\n",
      "Epoch 1/15\n",
      "28543/28543 [==============================] - 1s - loss: 0.6604 - binary_accuracy: 0.6108 - val_loss: 0.6615 - val_binary_accuracy: 0.6113\n",
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28543/28543 [==============================] - 1s - loss: 0.6553 - binary_accuracy: 0.6191 - val_loss: 0.6606 - val_binary_accuracy: 0.6151\n",
      "Epoch 3/15\n",
      "28543/28543 [==============================] - 1s - loss: 0.6542 - binary_accuracy: 0.6195 - val_loss: 0.6613 - val_binary_accuracy: 0.6122\n",
      "Test accuracy: 0.6245428175955676\n",
      "(31715, 14) (31715,) (7929, 14) (7929,)\n",
      "Train on 28543 samples, validate on 3172 samples\n",
      "Epoch 1/15\n",
      "28543/28543 [==============================] - 1s - loss: 0.6608 - binary_accuracy: 0.6100 - val_loss: 0.6628 - val_binary_accuracy: 0.6132\n",
      "Epoch 2/15\n",
      "28543/28543 [==============================] - 1s - loss: 0.6555 - binary_accuracy: 0.6173 - val_loss: 0.6601 - val_binary_accuracy: 0.6160\n",
      "Epoch 3/15\n",
      "28543/28543 [==============================] - 1s - loss: 0.6545 - binary_accuracy: 0.6188 - val_loss: 0.6634 - val_binary_accuracy: 0.6047\n",
      "Test accuracy: 0.618867448613899\n",
      "[' data_channel_is_lifestyle', ' weekday_is_friday', ' data_channel_is_bus', ' data_channel_is_tech', ' weekday_is_monday', ' weekday_is_wednesday', ' weekday_is_thursday', ' weekday_is_tuesday', ' is_weekend', ' data_channel_is_world', ' data_channel_is_entertainment', ' n_tokens_title', ' title_sentiment_polarity', ' global_sentiment_polarity']\n",
      "Evalutation of best performing model:\n",
      "6432/7929 [=======================>......] - ETA: 0s0.6526225797163913 0.6264346071609048\n",
      "Best performing model chosen hyper-parameters:\n",
      "{'Dense': 3, 'Dense_1': 4, 'batch_size': 2, 'optimizer': 1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_model(X_train, X_test, y_train, y_test):\n",
    "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, kernel_initializer='random_uniform', activation='relu', input_dim=X_train.shape[1]))\n",
    "    model.add(Dense({{choice([32,64, 128 ,256, 512, 1024])}}, activation='relu'))\n",
    "    model.add(Dense({{choice([32,64, 128 ,256, 512, 1024])}}, activation='relu'))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer={{choice(['rmsprop', 'adam', 'sgd'])}},\n",
    "                  loss=binary_crossentropy, metrics=[binary_accuracy])\n",
    "    history = model.fit(np.array(X_train), np.array(y_train), epochs=15, batch_size={{choice([32, 64, 128])}}, validation_split=0.1, callbacks=[EarlyStopping(monitor='val_loss', mode='auto')])\n",
    "    score, acc = model.evaluate(np.array(X_test), np.array(y_test), verbose=0)\n",
    "    print('Test accuracy:', acc)\n",
    "    \n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
    "best_run, best_model = optim.minimize(model=create_model,\n",
    "                                          data=data,\n",
    "                                          algo=tpe.suggest,\n",
    "                                          max_evals=5,\n",
    "                                          trials=Trials(),\n",
    "                                          notebook_name='fully_connected_binary')\n",
    "X_train, X_test, y_train, y_test = data()\n",
    "print(\"Evalutation of best performing model:\")\n",
    "score, acc = best_model.evaluate(np.array(X_test), np.array(y_test))\n",
    "print(score, acc)\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save best model\n",
    "def save_model(model,model_name, weights_name):\n",
    "    model_json = model.to_json()\n",
    "    with open(model_name, \"w\") as f:\n",
    "        f.write(model_json)\n",
    "    model.save_weights(weights_name)\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "save_model(best_model, 'models/binary_model.json', 'models/binary_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46900886]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict(np.array(X_train[:1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
